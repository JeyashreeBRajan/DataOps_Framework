name: Run Weather ETL DAG

on:
  workflow_dispatch:  # Allows manual trigger

jobs:
  run-dag:
    runs-on: ubuntu-latest

    env:
      AIRFLOW_HOME: ${{ github.workspace }}/airflow_home
      PYTHONPATH: ${{ github.workspace }}

    steps:
      # 1️⃣ Checkout the repo
      - name: Checkout code
        uses: actions/checkout@v3

      # 2️⃣ Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      # 3️⃣ Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "apache-airflow==2.9.3" --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.9.3/constraints-3.11.txt"
          pip install pandas numpy psycopg2-binary soda-sql

      # 4️⃣ Create Airflow folders
      - name: Create Airflow directories
        run: |
          mkdir -p $AIRFLOW_HOME/dags
          mkdir -p $AIRFLOW_HOME/logs
          mkdir -p $AIRFLOW_HOME/plugins
          cp -r e_dags/* $AIRFLOW_HOME/dags/

      # 5️⃣ Initialize the Airflow DB
      - name: Initialize Airflow database
        run: airflow db init

      # 6️⃣ List all DAGs to check registration
      - name: List all DAGs
        run: airflow dags list

      # 7️⃣ Trigger the DAG
      - name: Trigger Weather ETL DAG
        run: airflow dags trigger weather_pipeline