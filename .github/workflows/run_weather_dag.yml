name: Run Weather ETL DAG

on:
  workflow_dispatch:

jobs:
  run-dag:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2️⃣ Set up Python
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      # 3️⃣ Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "apache-airflow==2.9.3" --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.9.3/constraints-3.11.txt"
          pip install pandas numpy psycopg2-binary soda-core

      # 4️⃣ Set environment variables
      - name: Set AIRFLOW_HOME and PYTHONPATH
        run: |
          export AIRFLOW_HOME=$GITHUB_WORKSPACE/airflow_home
          export PYTHONPATH=$GITHUB_WORKSPACE:$PYTHONPATH
          echo "AIRFLOW_HOME=$AIRFLOW_HOME" >> $GITHUB_ENV
          echo "PYTHONPATH=$PYTHONPATH" >> $GITHUB_ENV

      # 5️⃣ Create airflow_home directories
      - name: Create DAGs folder
        run: |
          mkdir -p $AIRFLOW_HOME/dags
          mkdir -p $AIRFLOW_HOME/logs

      # 6️⃣ Copy DAGs to airflow_home
      - name: Copy DAGs
        run: cp e_dags/*.py $AIRFLOW_HOME/dags/

      # 7️⃣ Initialize Airflow DB
      - name: Initialize Airflow DB
        run: airflow db init

      # 8️⃣ List DAGs (verify)
      - name: List Airflow DAGs
        run: airflow dags list

      # 9️⃣ Trigger the DAG
      - name: Trigger Weather DAG
        run: airflow dags trigger weather_pipeline
