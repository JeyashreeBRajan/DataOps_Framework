name: Run Weather ETL DAG

on:
  workflow_dispatch:  # Manual trigger

jobs:
  run-dag:
    runs-on: ubuntu-latest

    env:
      AIRFLOW_HOME: ${{ github.workspace }}/airflow_home
      PYTHONPATH: ${{ github.workspace }}

    steps:
      # 1️⃣ Checkout repo
      - name: Checkout code
        uses: actions/checkout@v3

      # 2️⃣ Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      # 3️⃣ Install system dependencies
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libpq-dev python3-dev graphviz

      # 4️⃣ Upgrade pip and install Cython first
      - name: Upgrade pip and install Cython
        run: |
          python -m pip install --upgrade pip setuptools wheel Cython

      # 5️⃣ Install Python dependencies including Airflow
      - name: Install Python dependencies
        run: |
          pip install "apache-airflow==2.9.3" --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.9.3/constraints-3.11.txt"
          pip install pandas numpy psycopg2-binary soda-sql

      # 6️⃣ Create Airflow directories and copy DAGs
      - name: Create Airflow directories
        run: |
          mkdir -p $AIRFLOW_HOME/dags
          mkdir -p $AIRFLOW_HOME/logs
          mkdir -p $AIRFLOW_HOME/plugins
          cp -r e_dags/* $AIRFLOW_HOME/dags/

      # 7️⃣ Initialize Airflow DB
      - name: Initialize Airflow database
        run: airflow db init

      # 8️⃣ List all DAGs to ensure registration
      - name: List all DAGs
        run: airflow dags list

      # 9️⃣ Trigger the Weather ETL DAG
      - name: Trigger Weather ETL DAG
        run: airflow dags trigger weather_pipeline
